== Additional BF16 vector compute support extension *Zvfbfa*, Version 0.1

The Zvfbfa extension adds more complete BF16 vector compute support.

The Zvfbfa extension requires the Zve32f and Zfbfmin extensions.

NOTE: Zvfbfa is compatible with, but does not require, Zvfbfwma and
Zvfbfmin.

Zvfbfa adds a 1-bit field, `altfmt`, to the `vtype` CSR in bit position 8.
Attempting to set `altfmt`=1 and SEW >= 32 is reserved.

NOTE: The recommended assembly syntax to set `altfmt`=1 is to append the token
`alt` to the SEW setting, e.g. `vsetvli a0, a1, e16alt, m1, ta, ma`.

NOTE: Implementations should set `vill` in `vtype` when a reserved combination
of `altfmt` and SEW is selected.

When `altfmt`=0, the hart behaves as though Zvfbfa were not implemented.

When `altfmt`=1 and SEW=8, all vector floating-point instructions become
reserved, except for the following, which are redefined to use the BF16
format for any operand that would otherwise have used the FP16 format:

- `vfwcvt.f.x[u].v`
- `vfncvt.x[u].f.w`
- `vfncvt.rtz.x[u].f.w`

When `altfmt`=1 and SEW=16, all vector floating-point instructions become
reserved, except for the following, which are redefined to use the BF16
format for any operand that would otherwise have used the FP16 format:

- `vfadd.v[vf]`
- `vfsub.v[vf]`
- `vfmin.v[vf]`
- `vfmax.v[vf]`
- `vfsgnj.v[vf]` ††
- `vfsgnjn.v[vf]` ††
- `vfsgnjx.v[vf]` ††
- `vfslide1up.vf` ††
- `vfslide1down.vf` ††
- `vfmv.v.f` ††
- `vfmerge.vfm` ††
- `vmfeq.v[vf]`
- `vmfle.v[vf]`
- `vmflt.v[vf]`
- `vmfne.v[vf]`
- `vmfgt.vf`
- `vmfge.vf`
- `vfmul.v[vf]`
- `vfrsub.vf`
- `vfmadd.v[vf]`
- `vfnmadd.v[vf]`
- `vfmsub.v[vf]`
- `vfnmsub.v[vf]`
- `vfmacc.v[vf]`
- `vfnmacc.v[vf]`
- `vfmsac.v[vf]`
- `vfnmsac.v[vf]`
- `vfwadd.v[vf]`
- `vfwsub.v[vf]`
- `vfwadd.w[vf]`
- `vfwsub.w[vf]`
- `vfwmul.v[vf]`
- `vfwmacc.v[vf]` (same semantics as `vfwmaccbf16.v[vf]`)
- `vfwnmacc.v[vf]`
- `vfwmsac.v[vf]`
- `vfwnmsac.v[vf]`
- `vfmv.s.f` ††
- `vfmv.f.s` †
- `vfwcvt.f.f.v` (same semantics as `vfwcvtbf16.f.f.v`)
- `vfncvt.f.f.w` (same semantics as `vfncvtbf16.f.f.w`)
- `vfncvt.rod.f.f.w`
- `vfrsqrt7.v`
- `vfrec7.v`
- `vfclass.v`
- `vfwmaccbf16.v[vf]` †
- `vfwcvtbf16.f.f.v` †
- `vfncvtbf16.f.f.w` †

The instructions marked with † have the same semantics regardless of `altfmt`.
The instructions marked with †† differ only in that improperly NaN-boxed
`f`-register operands must substitute the BF16 canonical NaN instead of the
FP16 canonical NaN.

NOTE: The excluded operations are division, square root, reductions, and
conversions to/from integers wider than 8 bits.
These operations can be performed by converting to and from FP32.

For `vfrec7.v`, some inputs greater than 2^126^ produce subnormal results that
cannot be exactly represented in BF16's limited precision.
These results are rounded towards zero.



== OFP8 conversion extension *Zvfofp8min*, Version 0.1

The Zvfofp8min extension provides basic support for the two 8-bit
floating-point formats defined in the
https://www.opencompute.org/documents/ocp-8-bit-floating-point-specification-ofp8-revision-1-0-2023-12-01-pdf-1[Open Compute Project OFP8 specification],
OFP8 E4M3 and OFP8 E5M2.

NOTE: In some applications, the OFP8 formats are used to directly represent
numerical values.
In other applications, they are used as components of a block floating-point
format, such as the one described in the
https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf[OCP
Microscaling specification].
The conversion instructions defined in this extension support both use cases.
Software can convert OFP8 values to BF16 or FP32, then apply the scaling factor
in the higher-precision format, using, for example, a `vfmul.vf` instruction.
Future vector or matrix extensions might provide direct support for
microscaling if the need becomes quantitatively demonstrable.

NOTE: Only vector support for the OFP8 formats is currently proposed, as these
formats are used almost exclusively in highly data-parallel computations.

The canonical NaN for both E4M3 and E5M2 is `0x7f`.

=== OFP8 to BF16 conversion instructions

The existing `vfwcvt.f.f.v` instruction is used to convert from the OFP8
formats to BF16.
When SEW=8 and `altfmt`=0, this instruction converts a vector of OFP8 E4M3
values in `vs2` to a vector of BF16 values, writing the result to `vd`.
These instructions do not set any floating-point exception flags.
When SEW=8 and `altfmt`=1, the instruction treats `vs2` as a vector of OFP8
E5M2 values instead.

NOTE: Conversion to FP32, FP16, and integer formats is accomplished by first
converting to BF16, then using existing instructions in the Zvfbfmin, Zvfbfa,
Zvfhmin, and Zve32f extensions.
Conversion from OFP8 directly to FP32 is not a common operation, as OFP8 values
are typically used as multiplicands.
The multiplication operation can itself widen the result if needed.

NOTE: Conversion between the two OFP8 formats is an uncommon operation, but it
can be accomplished by first converting to BF16, then using one of the
instructions defined in the following section.

=== BF16 to OFP8 conversion instructions

The existing `vfncvt.f.f.w` instruction is used to convert from BF16 to the
OFP8 formats.
When SEW=8 and `altfmt`=0, this instruction converts a vector of BF16 values in
`vs2` to a vector of OFP8 E4M3 values, writing the result to `vd`.
Conversions that would overflow produce the canonical NaN, since E4M3 cannot
represent infinity.
Results are rounded using the dynamic rounding mode in the `frm` register, and
exceptions are reported in the `fflags` register as with other floating-point
conversions.
When SEW=8 and `altfmt`=1, the instruction converts to OFP8 E5M2 instead.
In this case, however, conversions that overflow produce an infinity of the
same sign as the input.

The OFP8 standard additionally defines saturating conversions, in which any
conversion that would have produced an infinite result instead produces the
maximum-magnitude finite value of the same size.
A new instruction, `vfncvt.sat.f.f.w`, implements this operation.
It is defined for SEW=8 and `altfmt`=0, and for SEW=8 and `altfmt`=1,
performing the same function as `vfncvt.f.f.w` except for the saturation
property.
It is encoded like `vfncvt.f.f.w`, but with `vs1`=11101.

NOTE: Conversion from 8-bit integer to OFP8 is accomplished by first converting
to BF16 using instructions in the Zvfbfa extension, then using the instructions
defined in this section.

=== FP32 to OFP8 conversion instructions

A new instruction to convert from FP32 to the OFP8 formats, `vfncvt.f.f.q`, is
added.
When SEW=8 and `altfmt`=0, this instruction converts a vector of FP32 values in
`vs2` (with EMUL=4×LMUL) to a vector of OFP8 E4M3 values, writing the result to
`vd` (with EMUL=LMUL).
Conversions that would overflow produce the canonical NaN, since E4M3 cannot
represent infinity.
Results are rounded using the dynamic rounding mode in the `frm` register, and
exceptions are reported in the `fflags` register as with other floating-point
conversions.
When SEW=8 and `altfmt`=1, the instruction converts to OFP8 E5M2 instead.
In this case, however, conversions that overflow produce an infinity of the
same sign as the input.
It is encoded like `vfncvt.f.f.w`, but with `vs1`=11110.

Another new instruction, `vfncvt.sat.f.f.q`, is defined for SEW=8 and
`altfmt`=0, and for SEW=8 and `altfmt`=1, performing the same function as the
`vfncvt.f.f.q` instruction, but saturating in the same manner as the
`vfncvt.sat.f.f.w` instruction.
It is encoded like `vfncvt.f.f.w`, but with `vs1`=11111.

NOTE: An alternative design would have been to first convert from FP32 to BF16,
rounding to odd, then use the instructions defined in the previous section to
convert to OFP8.
However, FP32 to OFP8 conversion is common enough to justify the direct
conversion.

NOTE: Conversion from FP16 and 16-bit integer formats is accomplished by first
converting to FP32 using instructions in the Zvfhmin and Zve32f extensions,
then using the instructions defined in this section.
